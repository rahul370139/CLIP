{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading clip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CLIP model\n",
    "model_name = \"ViT-B/32\"\n",
    "model, preprocess = clip.load(model_name, device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "image_folder = \"/Users/rahul/Downloads/deepfashion1_data/images/\"\n",
    "segm_folder = \"/Users/rahul/Downloads/deepfashion1_data/segm/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing of images using segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to apply segmentation mask\n",
    "def apply_mask(original_img_path, segm_mask_path):\n",
    "    img = Image.open(original_img_path).convert('RGB')\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    mask = Image.open(segm_mask_path).convert('L')\n",
    "    mask = mask.resize(img.size, Image.NEAREST)\n",
    "    mask_np = np.array(mask)\n",
    "\n",
    "    # Binary mask where clothing pixels > 0\n",
    "    binary_mask = (mask_np > 0).astype(np.uint8)\n",
    "\n",
    "    # Black out non-clothing pixels\n",
    "    img_np[binary_mask == 0] = 0\n",
    "\n",
    "    masked_img = Image.fromarray(img_np)\n",
    "    return masked_img\n",
    "\n",
    "# Get list of images (assuming all have corresponding segm masks)\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "storing embedding of all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 44096/44096 [8:38:50<00:00,  1.42it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Embeddings saved to 'masked_image_embeddings.npy'.\n"
     ]
    }
   ],
   "source": [
    "# Prepare arrays/lists to store data\n",
    "all_embeddings = []\n",
    "all_image_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in tqdm(image_files, desc=\"Processing dataset\"):\n",
    "        # Construct paths\n",
    "        base_name, ext = os.path.splitext(img_name)\n",
    "        segm_name = base_name + \"_segm.png\"  \n",
    "        segm_path = os.path.join(segm_folder, segm_name)\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "\n",
    "        # Check if mask exists\n",
    "        if not os.path.exists(segm_path):\n",
    "            masked_img = Image.open(img_path).convert('RGB')\n",
    "        else:\n",
    "            masked_img = apply_mask(img_path, segm_path)\n",
    "\n",
    "        # Preprocess and encode the masked image\n",
    "        image_input = preprocess(masked_img).unsqueeze(0).to(device)\n",
    "        image_feature = model.encode_image(image_input)\n",
    "        image_feature = image_feature / image_feature.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Convert to numpy and store\n",
    "        embedding_np = image_feature.cpu().numpy()\n",
    "        all_embeddings.append(embedding_np)\n",
    "        \n",
    "        # Store full path directly here\n",
    "        all_image_paths.append(img_path)\n",
    "\n",
    "# Stack all embeddings into a single NumPy array: shape (num_images, embed_dim)\n",
    "all_embeddings = np.vstack(all_embeddings)\n",
    "\n",
    "# Save embeddings and corresponding image paths for future use\n",
    "np.save(\"masked_image_embeddings.npy\", all_embeddings)\n",
    "print(\"Processing complete. Embeddings saved to 'masked_image_embeddings.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading image saved file and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"masked_image_paths.txt\", \"w\") as f:\n",
    "    for img_name in all_image_paths:\n",
    "        full_path = os.path.join(image_folder, img_name)\n",
    "        f.write(full_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 44096 embeddings and image paths.\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "all_embeddings = np.load(\"masked_image_embeddings.npy\")  # shape: (num_images, embed_dim)\n",
    "\n",
    "# Load image paths\n",
    "with open(\"masked_image_paths.txt\", \"r\") as f:\n",
    "    all_image_paths = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# all_image_paths = [os.path.join(image_folder, p) for p in all_image_paths]\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(all_image_paths)} embeddings and image paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    image_input = preprocess(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_feature = model.encode_image(image_input)\n",
    "    image_feature = image_feature / image_feature.norm(dim=-1, keepdim=True)\n",
    "    return image_feature.cpu().numpy()  # (1, embed_dim)\n",
    "\n",
    "def get_text_embedding(user_text):\n",
    "    text_tokens = clip.tokenize([user_text]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feature = model.encode_text(text_tokens)\n",
    "    text_feature = text_feature / text_feature.norm(dim=-1, keepdim=True)\n",
    "    return text_feature.cpu().numpy()  # (1, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_embeddings(image_embed, text_embed, alpha):\n",
    "    # alpha for text, (1 - alpha) for image\n",
    "    combined = (alpha * text_embed) + ((1 - alpha) * image_embed)\n",
    "    combined = combined / np.linalg.norm(combined, axis=1, keepdims=True)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_images(query_embedding, dataset_embeddings, dataset_paths, top_k):\n",
    "    # query_embedding: (1, embed_dim)\n",
    "    similarities = cosine_similarity(query_embedding, dataset_embeddings)  # (1, num_images)\n",
    "    similarities = similarities.flatten()\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    top_indices = sorted_indices[:top_k]\n",
    "    results = [(dataset_paths[i], similarities[i]) for i in top_indices]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image similarity only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches for image-only query:\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00005097-05_1_front.jpg - similarity: 1.0000\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00005528-06_1_front.jpg - similarity: 0.9541\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00005097-08_4_full.jpg - similarity: 0.9450\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00007583-01_1_front.jpg - similarity: 0.9410\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00007564-01_2_side.jpg - similarity: 0.9391\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00004235-01_1_front.jpg - similarity: 0.9391\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00007564-01_1_front.jpg - similarity: 0.9378\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00007564-03_1_front.jpg - similarity: 0.9314\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00005097-04_2_side.jpg - similarity: 0.9309\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00007583-03_1_front.jpg - similarity: 0.9293\n"
     ]
    }
   ],
   "source": [
    "user_image_path = \"/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00005097-05_1_front.jpg\"\n",
    "user_image_embed = get_image_embedding(user_image_path)\n",
    "results = find_similar_images(user_image_embed, all_embeddings, all_image_paths, top_k=10)\n",
    "\n",
    "print(\"Top matches for image-only query:\")\n",
    "for path, score in results:\n",
    "    print(f\"{path} - similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_text = \"Hi, can you please provide me some men shorts of any colors\"\n",
    "# user_text_embed = get_text_embedding(user_text)\n",
    "# results = find_similar_images(user_text_embed, all_embeddings, all_image_paths, top_k=10)\n",
    "\n",
    "# print(\"Top matches for text-only query:\")\n",
    "# for path, score in results:\n",
    "#     print(f\"{path} - similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image and text input from user and finding similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial combined results (equal weight):\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Shirts_Polos-id_00001802-02_1_front.jpg - similarity: 0.5813\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Sweaters-id_00001783-01_4_full.jpg - similarity: 0.5603\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Sweaters-id_00005021-01_1_front.jpg - similarity: 0.5602\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00001903-01_1_front.jpg - similarity: 0.5577\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00001705-03_7_additional.jpg - similarity: 0.5572\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00001705-03_2_side.jpg - similarity: 0.5563\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00001903-03_1_front.jpg - similarity: 0.5552\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Sweaters-id_00001008-05_1_front.jpg - similarity: 0.5538\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00004902-02_1_front.jpg - similarity: 0.5535\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00005629-03_1_front.jpg - similarity: 0.5534\n",
      "Reranked results (more text weight):\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00004902-02_1_front.jpg - similarity: 0.4063\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00001705-03_7_additional.jpg - similarity: 0.3979\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00001705-03_2_side.jpg - similarity: 0.3918\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/WOMEN-Jackets_Coats-id_00005629-03_1_front.jpg - similarity: 0.3894\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00001903-01_1_front.jpg - similarity: 0.3757\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Jackets_Vests-id_00001903-03_1_front.jpg - similarity: 0.3748\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Sweaters-id_00005021-01_1_front.jpg - similarity: 0.3665\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Sweaters-id_00001783-01_4_full.jpg - similarity: 0.3610\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Sweaters-id_00001008-05_1_front.jpg - similarity: 0.3609\n",
      "/Users/rahul/Downloads/deepfashion1_data/images/MEN-Shirts_Polos-id_00001802-02_1_front.jpg - similarity: 0.3599\n"
     ]
    }
   ],
   "source": [
    "user_image_path = \"/Users/rahul/Downloads/deepfashion1_data/images/MEN-Shirts_Polos-id_00001802-02_1_front.jpg\"\n",
    "user_text = \"Show me professional outfits like this, but with a neutral blazer with full sleeves for my sister.\"\n",
    "user_image_embed = get_image_embedding(user_image_path)\n",
    "user_text_embed = get_text_embedding(user_text)\n",
    "\n",
    "# First pass: equal weighting\n",
    "combined_embed = combine_embeddings(user_image_embed, user_text_embed, alpha=0.7)\n",
    "initial_results = find_similar_images(combined_embed, all_embeddings, all_image_paths, top_k=10)\n",
    "\n",
    "print(\"Initial combined results (equal weight):\")\n",
    "for path, score in initial_results:\n",
    "    print(f\"{path} - similarity: {score:.4f}\")\n",
    "\n",
    "# Optional second pass: rerank with heavier text weight if desired\n",
    "rerank_alpha = 0.9\n",
    "rerank_embed = combine_embeddings(user_image_embed, user_text_embed, alpha=rerank_alpha)\n",
    "\n",
    "# Just re-check top candidates from initial_results\n",
    "candidate_paths = [res[0] for res in initial_results]\n",
    "candidate_embs = []\n",
    "for cpath in candidate_paths:\n",
    "    idx = all_image_paths.index(cpath)\n",
    "    candidate_embs.append(all_embeddings[idx][None, :])\n",
    "candidate_embs = np.vstack(candidate_embs)\n",
    "\n",
    "similarities = cosine_similarity(rerank_embed, candidate_embs).flatten()\n",
    "sorted_indices = np.argsort(similarities)[::-1]\n",
    "final_results = [(candidate_paths[i], similarities[i]) for i in sorted_indices]\n",
    "\n",
    "print(\"Reranked results (more text weight):\")\n",
    "for path, score in final_results:\n",
    "    print(f\"{path} - similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
